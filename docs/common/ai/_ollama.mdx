Ollama 是一款高效的本地大语言模型（LLM）管理与运行工具。
它极大地简化了 AI 模型的部署流程，让用户无需复杂的环境配置，即可在本地设备上实现模型的一键拉取、运行与统一管理。

## Ollama 安装

```bash
curl -fsSL https://ollama.com/install.sh | sh
```

本地构建方法请参考 [官方文档](https://github.com/ollama/ollama/blob/main/docs/development.md)

## 使用方法

### 拉取模型

此命令会通过互联网下载模型文件。

```bash
ollama pull deepseek-r1:1.5b
```

### 运行模型

此命令会直接启动模型，若无本地缓存，则自动联网下载并运行。

```bash
ollama run deepseek-r1:1.5b
```

### 显示模型信息

```bash
ollama show deepseek-r1:1.5b
```

### 列出已下载的模型

```bash
ollama list
```

### 列出已加载的模型

```bash
ollama ps
```

### 停止正在运行的模型

```bash
ollama stop deepseek-r1:1.5b
```

### 删除模型

```bash
ollama rm deepseek-r1:1.5b
```

## 参考信息

更多关于 Ollama 的详细资料，请参考 [官方文档](https://github.com/ollama/ollama)
