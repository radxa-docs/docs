:::tip
本文档旨在演示如何在 x86 PC 上使用 rknn-toolkit2 脱离开发板模拟推理 YOLOv5 目标分割模型，所需环境配置请参考[ RKNN 安装](./rknn_install)
:::

## 准备模型

此示例用 [rknn_model_zoo](https://github.com/airockchip/rknn_model_zoo) 中预训练好的 ONNX 格式模型为例子通过模型转换, 并在 PC 端做模拟推理。

- 如使用 conda 请先激活 rknn conda 环境

  <NewCodeBlock tip="X86 Linux PC" type="PC">

  ```bash
  conda activate rknn
  ```

  </NewCodeBlock>

- 下载 yolov5s-seg.onnx 模型

  <NewCodeBlock tip="X86 Linux PC" type="PC">

  ```bash
  cd rknn_model_zoo/examples/yolov5_seg/model
  # 下载预训练好的 yolov5s-seg.onnx 模型
  bash download_model.sh
  ```

  </NewCodeBlock>

  :::tip
  如遇到网络问题，可访问 [此页 ](https://github.com/airockchip/rknn_model_zoo?tab=readme-ov-file#model-support) 下载对应的模型到对应文件夹
  :::

- 修改 onnx 模型后缀为 rknn (**仅用于 PC 端结果模拟**)

  <NewCodeBlock tip="X86 Linux PC" type="PC">

  ```bash
  cp yolov5s-seg.onnx yolov5s-seg.rknn
  ```

  </NewCodeBlock>

- （可选）使用 rknn-toolkit2 转换成 yolov5s-seg.rknn

  <NewCodeBlock tip="X86 Linux PC" type="PC">

  ```bash
  cd rknn_model_zoo/examples/yolov5_seg/python
  python3 convert.py <onnx_model> <TARGET_PLATFORM> <dtype> <output_rknn_path>
  # python3 convert.py ../model/yolov5s-seg.onnx rk3588 i8 ../model/yolov5s-seg.rknn
  ```

  </NewCodeBlock>

  参数解析：

  `<onnx_model>`: 指定 ONNX 模型路径

  `<TARGET_PLATFORM>`: 指定 NPU 平台名称。可选 `rk3562, rk3566, rk3568, rk3576, rk3588, rk1808, rv1109, rv1126`

  `<dtype>`: 指定为 `i8` 或 `fp`。`i8` 用于 int8 量化，`fp` 用于 fp16 量化。默认为 `i8`

  `<output_rknn_path>`: 指定RKNN模型的保存路径，默认保存在与ONNX模型相同的目录中，文件名为 `yolov5s-seg.rknn`
  :::tip
  RK358X 用户 TARGET_PLATFORM 请指定 `rk3588` 平台
  :::

## PC 真实推理 onnx 模型

<NewCodeBlock tip="X86 Linux PC" type="PC">

```bash
python3 yolov5_seg.py --model_path ../model/yolov5s-seg.onnx --img_show
```

</NewCodeBlock>

<NewCodeBlock tip="Result" type="PC">

```bash
person @ (212 242 285 510) 0.871
person @ (111 240 223 535) 0.850
person @ (472 233 559 519) 0.831
bus  @ (97 134 549 458) 0.799
person @ (80 328 125 517) 0.470
```

</NewCodeBlock>

<img width="550" src="/img/general-tutorial/rknn/yolov5_seg_onnx_result.webp" />

## PC 模拟推理 rknn 模型

- pip3 安装所需依赖

  <NewCodeBlock tip="X86 Linux PC" type="PC">

  ```bash
  pip3 install torchvision==0.19.0 pycocotools
  ```

  </NewCodeBlock>

- 运行模拟推理程序

  - 修改 rknn_model_zoo/py_utils/rknn_executor.py 为以下代码，**务必备份一份原版代码**

    <NewCodeBlock tip="Python Code" type="PC">

    ```python
    from rknn.api import RKNN

    class RKNN_model_container():
        def __init__(self, model_path, target=None, device_id=None) -> None:
            rknn = RKNN()
            DATASET_PATH = '../../../datasets/COCO/coco_subset_20.txt'
            onnx_model = model_path[:-4] + 'onnx'
            rknn.config(mean_values=[[0, 0, 0]], std_values=[[255, 255, 255]], target_platform=target)
            rknn.load_onnx(model=onnx_model)
            rknn.build(do_quantization=True, dataset=DATASET_PATH)
            rknn.init_runtime()
            self.rknn = rknn

        def run(self, inputs):
            if isinstance(inputs, list) or isinstance(inputs, tuple):
                pass
            else:
                inputs = [inputs]

            result = self.rknn.inference(inputs=inputs)
            return result

        def release(self):
            self.rknn.release()
            self.rknn = None
    ```

    </NewCodeBlock>

  - 运行模拟推理程序

      <NewCodeBlock tip="X86 Linux PC" type="PC">

    ```bash
    python3 yolov5_seg.py --target <TARGET_PLATFORM> --model_path <RKNN_MODEL_PATH> --img_show
    # python3 yolov5_seg.py --target rk3588 --model_path ../model/yolov5s-seg.rknn --img_show
    ```

      </NewCodeBlock>

    `--target`: 指定模拟 NPU 平台名称。可选 `rk3562, rk3566, rk3568, rk3576, rk3588, rk1808, rv1109, rv1126`

    `--model_path`: 需要模拟的 rknn 模型路径

      <NewCodeBlock tip="Results" type="PC">

    ```bash
    person @ (213 239 284 516) 0.882
    person @ (109 240 224 535) 0.869
    person @ (473 231 560 523) 0.845
    bus  @ (97 136 548 459) 0.821
    person @ (80 328 124 519) 0.499
    ```

      </NewCodeBlock>

  - 模拟推理结果 （模拟器仅模拟 NPU 计算结果，实际效果与精度以板端推理为准）

<img width="550" src="/img/general-tutorial/rknn/yolov5_seg_result.webp" />
