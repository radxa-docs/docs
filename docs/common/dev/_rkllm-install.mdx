## RKLLM 简介

RKLLM 可以帮助用户快速将 LLM 模型部署到 Rockchip 芯片中，目前支持芯片：RK3588/RK3576/RK3562 系列芯片。

RKLLM 整体框架如下：

![rkllm_1.webp](/img/general-tutorial/rknn/rkllm_1.webp)

#### 目前支持模型

- [LLAMA models](https://huggingface.co/meta-llama)
- [TinyLLAMA models](https://huggingface.co/TinyLlama)
- [Qwen models](https://huggingface.co/models?search=Qwen/Qwen)
- [Phi models](https://huggingface.co/models?search=microsoft/phi)
- [ChatGLM3-6B](https://huggingface.co/THUDM/chatglm3-6b/tree/103caa40027ebfd8450289ca2f278eac4ff26405)
- [Gemma2](https://huggingface.co/collections/google/gemma-2-release-667d6600fd5220e7b967f315)
- [Gemma3](https://huggingface.co/collections/google/gemma-3-release-67c6c6f89c4f76621268bb6d)
- [InternLM2 models](https://huggingface.co/collections/internlm/internlm2-65b0ce04970888799707893c)
- [MiniCPM models](https://huggingface.co/collections/openbmb/minicpm-65d48bf958302b9fd25b698f)
- [TeleChat models](https://huggingface.co/Tele-AI)
- [Qwen2-VL-2B-Instruct](https://huggingface.co/Qwen/Qwen2-VL-2B-Instruct)
- [MiniCPM-V-2_6](https://huggingface.co/openbmb/MiniCPM-V-2_6)
- [DeepSeek-R1-Distill](https://huggingface.co/collections/deepseek-ai/deepseek-r1-678e1e131c0169c0bc89728d)
- [Janus-Pro-1B](https://huggingface.co/deepseek-ai/Janus-Pro-1B)
- [InternVL2-1B](https://huggingface.co/OpenGVLab/InternVL2-1B)
- [Qwen2.5-VL-3B-Instruct](https://huggingface.co/Qwen/Qwen2.5-VL-3B-Instruct)
- [Qwen3](https://huggingface.co/collections/Qwen/qwen3-67dd247413f0e2e4f653967f)

## 下载 SDK

进入统一存放 SDK 的目录并克隆 RKLLM 仓库。

<NewCodeBlock tip="X86 Linux PC" type="PC">

```bash
cd RKSDK
git clone -b release-v1.2.3 https://github.com/airockchip/rknn-llm.git
```

</NewCodeBlock>

## 安装 Miniforge

<NewCodeBlock tip="X86 Linux PC" type="PC">

```bash
wget https://github.com/conda-forge/miniforge/releases/download/25.11.0-0/Miniforge3-25.11.0-0-Linux-x86_64.sh
chmod +x Miniforge3-25.11.0-0-Linux-x86_64.sh
bash Miniforge3-25.11.0-0-Linux-x86_64.sh
```

</NewCodeBlock>

## 创建虚拟环境

<NewCodeBlock tip="X86 Linux PC" type="PC">

```bash
conda create -n rkllm python=3.12
```

</NewCodeBlock>

## 激活虚拟环境

<NewCodeBlock tip="X86 Linux PC" type="PC">

```bash
conda activate rkllm
```

</NewCodeBlock>

## 安装依赖包

<NewCodeBlock tip="X86 Linux PC" type="PC">

```bash
cd rknn-llm/rkllm-toolkit/packages
pip install rkllm_toolkit-1.2.3-cp312-cp312-linux_x86_64.whl
```

</NewCodeBlock>

## 验证安装

若执行以下命令没有报错，则安装成功。

<NewCodeBlock tip="X86 Linux PC" type="PC">

```bash
$python3
>>>from rkllm.api import RKLLM
```

</NewCodeBlock>

## 编译工具

编译板端运行代码时需要用到交叉编译工具链。

点击下载：[交叉编译工具链](https://developer.arm.com/-/media/files/downloads/gnu/11.2-2022.02/binrel/gcc-arm-11.2-2022.02-x86_64-aarch64-none-linux-gnu.tar.xz?rev=33c6e30e5ac64e6dba8f0431f2c35f1b&revision=33c6e30e-5ac6-4e6d-ba8f-0431f2c35f1b&hash=632C6C0BD43C3E4B59CA8A09A7055D30)。

下载完成之后解压即可。

编译前需要导出编译器路径到环境变量，让脚本能找到下载的交叉编译器。

<NewCodeBlock tip="X86 Linux PC" type="PC">

```bash
export GCC_COMPILER=/path/to/your/gcc/bin/aarch64-linux-gnu
```

</NewCodeBlock>

## 板端驱动配置

由于所提供的 RKLLM 所需要的 NPU 内核版本较高，用户在板端使用 RKLLM Runtime 进行模型推理前，首先需要确认板端的 NPU 内核是否为 v0.9.8 版本。

:::tip
radxa 6.1 固件默认 RKNPU 驱动版本为 0.9.6，请通过: `sudo rsetup` -> `System` -> `System Update` 升级系统以更新至 0.9.8 RKNPU 驱动。
升级后请务必执行 **`sudo apt autopurge`** 然后重启。
:::

查看驱动版本：

<NewCodeBlock tip="Radxa OS" type="device">

```bash
$ sudo cat /sys/kernel/debug/rknpu/version
RKNPU driver: v0.9.8
```

</NewCodeBlock>

（可选）手动编译 NPU 内核：

若用户所使用的为非官方固件，需要对内核进行更新；其中，RKNPU 驱动包支持两个主要内核版本：[kernel-5.10](https://github.com/radxa/kernel/tree/stable-5.10-rock5) 和 [kernel-6.1](https://github.com/radxa/kernel/tree/linux-6.1-stan-rkr1)；用户可在内核根目录下的 Makefile 中确认具体版本号。内核的具体的更新步骤如下：

1） 下载压缩包 [rknpu_driver_0.9.8_20241009.tar.bz2](https://github.com/airockchip/rknn-llm/tree/release-v1.2.1b1/rknpu-driver)。

2） 解压该压缩包，将其中的 rknpu 驱动代码覆盖到当前内核代码目录。

3） 重新编译内核。

4） 将新编译的内核烧录到设备中。

## 板端克隆仓库

RKLLM Runtime 为 Rockchip NPU 平台提供 C/C++ 编程接口，帮助用户部署 RKLLM 模型，加速 LLM 应用的实现。

在板端克隆 RKLLM 仓库：

<NewCodeBlock tip="Radxa OS" type="device">

```bash
git clone -b release-v1.2.3 https://github.com/airockchip/rknn-llm.git
```

</NewCodeBlock>
