[DeepSeek-R1](https://api-docs.deepseek.com/news/news250120) 是由杭州深度求索（DeepSeek）公司开发的顶尖推理模型。
该模型不仅完整开源了全套训练技术与模型权重，其性能表现更可比肩闭源的 OpenAI-o1。
此外，DeepSeek 官方还通过 DeepSeek-R1 的输出，通过知识蒸馏技术推出了 6 款开源轻量化模型（涵盖 Qwen2.5 和 Llama3.1 系列）。
本文档将详细演示如何利用 RKLLM 工具链，将蒸馏模型 DeepSeek-R1-Distill-Qwen-1.5B 部署至 RK3588 开发板，并调用其内置的 NPU 实现高效的硬件加速推理。

![rkllm_2.webp](/img/general-tutorial/rknn/rkllm_ds_1.webp)

## 快速开始

### 下载示例

从 ModelScope 下载完整示例。

<NewCodeBlock tip="Device" type="device">

```bash
pip install -U modelscope
modelscope download --model radxa/DeepSeek-R1-Distill-Qwen-1.5B_RKLLM
```

</NewCodeBlock>

### 运行示例

<NewCodeBlock tip="Device" type="device">

```bash
cd demo_Linux_aarch64/
export LD_LIBRARY_PATH=./lib
./llm_demo ../DeepSeek-R1-Distill-Qwen-1.5B_W8A8_RK3588.rkllm 2048 4096
```

</NewCodeBlock>

## 完整转换流程

:::info[先决条件]
根据 [RKLLM 安装](./rkllm-install)配置好开发环境。
:::

:::warning[版本问题]
在 rkllm 1.2.3 环境下运行此示例会导致严重的精度损失，触发模型‘复读机’效应（产生大量重复输出）而无法正常回复。
建议降级至 rkllm 1.2.2 版本以解决该问题，详情请参考 [GitHub Issue](https://github.com/airockchip/rknn-llm/issues/424) 。
:::

### 激活虚拟环境

<NewCodeBlock tip="X64 Linux PC" type="PC">

```bash
conda activate rkllm
pip install -U huggingface_hub
```

</NewCodeBlock>

### 下载模型

<NewCodeBlock tip="X64 Linux PC" type="PC">

```bash
cd RK-SDK/rknn-llm/examples/rkllm_api_demo/
hf download https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B --local-dir ./DeepSeek-R1-Distill-Qwen-1.5B
```

</NewCodeBlock>

### 模型转换

生成量化校准文件并将模型导出为 rkllm 模型。

:::tip
如对 max_context 长度有需求，可在 export_rkllm.py 中的 llm.build 函数接口中修改 max_context 参数的值，
默认是 4096, 值越大，占用内存越多。不得超过 16,384，且必须是 32 的倍数（例如，32、64、96、...、16,384）
:::

<NewCodeBlock tip="X64 Linux PC" type="PC">

```bash
cd export/
python generate_data_quant.py -m ../DeepSeek-R1-Distill-Qwen-1.5B -o ../DeepSeek-R1-Distill-Qwen-1.5B/data_quant.json
# 运行前修改模型路径和量化校准文件路径
python export_rkllm.py
```

</NewCodeBlock>

### 编译可执行文件

<NewCodeBlock tip="X64 Linux PC" type="PC">

```bash
cd ../deploy/
# 导出交叉编译器路径
export GCC_COMPILER=/path/to/your/gcc/bin/aarch64-linux-gnu
bash build-linux.sh
```

</NewCodeBlock>

生成的可执行文件在 `install/demo_Linux_aarch64`

### 板端部署

将转换成功后的模型与编译后生成的 `demo_Linux_aarch64` 目录传输到板端。

<NewCodeBlock tip="Device" type="device">

```bash
cd demo_Linux_aarch64/
export RKLLM_LOG_LEVEL=1
export LD_LIBRARY_PATH=./lib
./llm_demo ../DeepSeek-R1-Distill-Qwen-1.5B_W8A8_RK3588.rkllm 2048 4096
```

</NewCodeBlock>

运行示例，输入 exit 退出。

<NewCodeBlock tip="Device" type="device">

```bash
./llm_demo ../DeepSeek-R1-Distill-Qwen-1.5B_W8A8_RK3588.rkllm 2048 4096
```

</NewCodeBlock>

```bash
$ ./llm_demo ../DeepSeek-R1-Distill-Qwen-1.5B_W8A8_RK3588.rkllm 2048 4096
rkllm init start
I rkllm: rkllm-runtime version: 1.2.2, rknpu driver version: 0.9.8, platform: RK3588
I rkllm: loading rkllm model from ./DeepSeek-R1-Distill-Qwen-1.5B_W8A8_RK3588.rkllm
I rkllm: rkllm-toolkit version: 1.2.2, max_context_limit: 4096, npu_core_num: 3, target_platform: RK3588, model_dtype: W8A8
I rkllm: Enabled cpus: [4, 5, 6, 7]
I rkllm: Enabled cpus num: 4
rkllm init success

**********************可输入以下问题对应序号获取回答/或自定义输入********************

[0] 现有一笼子，里面有鸡和兔子若干只，数一数，共有头14个，腿38条，求鸡和兔子各有多少只？
[1] 有28位小朋友排成一行,从左边开始数第10位是学豆,从右边开始数他是第几位?

*************************************************************************


user: 0
现有一笼子，里面有鸡和兔子若干只，数一数，共有头14个，腿38条，求鸡和兔子各有多少只？
robot: <think>
首先，设鸡的数量为x只，兔子的数量为y只。

根据题意，头的总数是14个，因此可以得出方程：
x + y = 14

接下来，考虑腿的总数。每只鸡有2条腿，每只兔子有4条腿，腿的总数为38条，所以另一个方程为：
2x + 4y = 38

现在有两个方程：
1. x + y = 14
2. 2x + 4y = 38

通过代数方法解这个方程组。首先，将第一个方程中的x表示为：
x = 14 - y

然后，将其代入第二个方程：
2(14 - y) + 4y = 38
展开并简化方程得到：
28 - 2y + 4y = 38
合并同类项：
28 + 2y = 38
解出y的值：
2y = 10
y = 5

最后，将y=5代入x=14-y中得到：
x = 9

因此，鸡有9只，兔子有5只。
</think>

要解决这个问题，我们可以设：

- 鸡的数量为 \( x \) 只
- 兔子的数量为 \( y \) 只

根据题意，列出方程如下：

1. **头的总数**：每只动物各有一个头，所以：
   \[
   x + y = 14
   \]

2. **腿的总数**：鸡有两条腿，兔子有四条腿。总腿数为38条：
   \[
   2x + 4y = 38
   \]

接下来解这个方程组：

首先，简化第二个方程：
\[
2x + 4y = 38 \\
x + 2y = 19 \quad \text{(两边同时除以2)}
\]

然后，用代入法求解。从第一个方程中解出 \( x \)：
\[
x = 14 - y
\]

将 \( x = 14 - y \) 代入简化后的第二个方程：
\[
(14 - y) + 2y = 19 \\
14 + y = 19 \\
y = 5
\]

接下来，求出 \( x \)：
\[
x = 14 - y = 14 - 5 = 9
\]

因此，鸡有 **9** 只，兔子有 **5** 只。

\[
\boxed{鸡有9只，兔有5只}
\]
I rkllm: --------------------------------------------------------------------------------------
I rkllm:  Model init time (ms)  2082.90
I rkllm: --------------------------------------------------------------------------------------
I rkllm:  Stage         Total Time (ms)  Tokens    Time per Token (ms)      Tokens per Second
I rkllm: --------------------------------------------------------------------------------------
I rkllm:  Prefill       415.12           38        10.92                    91.54
I rkllm:  Generate      39445.01         585       67.43                    14.83
I rkllm: --------------------------------------------------------------------------------------
I rkllm:  Peak Memory Usage (GB)
I rkllm:  1.73
I rkllm: --------------------------------------------------------------------------------------
```

| 参数              | 必要性 | 描述                   | 选项                             |
| ----------------- | ------ | ---------------------- | -------------------------------- |
| `path`            | 必要   | RKLLM 模型文件夹路径。 | N                                |
| `max_new_tokens`  | 必要   | 每轮最大生成 token 数  | 小于等于 max_context_len         |
| `max_context_len` | 必要   | 模型最大上下文范围     | 小于等于模型转换时的 max_context |

### 性能分析

对于数学问题： `解方程 x+y=12, 2x+4y=34, 求x,y的值`，

在 RK3588 上达 15.36 token/s,

| Stage    | Total Time (ms) | Tokens | Time per Token (ms) | Tokens per Second |
| -------- | --------------- | ------ | ------------------- | ----------------- |
| Prefill  | 122.70          | 29     | 4.23                | 236.35            |
| Generate | 27539.16        | 423    | 65.10               | 15.36             |

在 RK3582 上达 10.61 token/s
| Stage | Total Time (ms) | Tokens | Time per Token (ms) | Tokens per Second |
|----------|-----------------|--------|---------------------|-------------------|
| Prefill | 599.71 | 81 | 7.4 | 135.07 |
| Generate | 76866.41 | 851 | 94.25 | 10.61 |
