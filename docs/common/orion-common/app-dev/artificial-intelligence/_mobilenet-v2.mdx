**MobileNet** 是由 Google 专门为移动端和嵌入式设备设计的轻量级深度神经网络系列。它通过革新卷积计算方式，大幅降低了模型的参数量与计算复杂度，使得高性能视觉算法能够在智能手机、物联网终端等算力受限的设备上实时运行。

- 核心特点：支持高效的图像分类、目标检测及语义分割，通过极低的延迟实现高质量的视觉感知，是移动端深度学习应用的核心引擎。
- 版本说明：本案例采用 MobileNetV2 模型。作为该系列的进阶版本，它采用了独特的“倒残差与线性瓶颈”架构，不仅提升了内存利用率，还增强了复杂特征的提取能力。它是目前移动视觉领域兼具极速推理与优秀精度的行业标杆，是端侧AI应用中最具性价比的平衡选择。

:::info[环境配置]
需要提前配置好相关环境。

- [环境配置](../../../../orion/o6/app-development/artificial-intelligence/env-setup.md)
- [AI Model Hub](../../../../orion/o6/app-development/artificial-intelligence/ai-hub.md)
  :::

## 快速开始

### 下载模型文件

<NewCodeBlock tip="O6 / O6N" type="device">

```bash
cd ai_model_hub_25_Q3/models/ComputeVision/Image_Classification/onnx_mobilenet_v2
wget -O mobilenet_v2.cix https://www.modelscope.cn/models/cix/ai_model_hub_25_Q3/resolve/master/models/ComputeVision/Image_Classification/onnx_mobilenet_v2/mobilenet_v2.cix
```

</NewCodeBlock>

### 模型测试

:::info
运行前激活虚拟环境！
:::

<NewCodeBlock tip="O6 / O6N" type="device">

```bash
python3 inference_npu.py
```

</NewCodeBlock>

## 完整转换流程

### 下载模型文件

<NewCodeBlock tip="Linux PC" type="PC">

```bash
cd ai_model_hub_25_Q3/models/ComputeVision/Image_Classification/onnx_mobilenet_v2/model
wget -O mobilenet_v2.onnx https://www.modelscope.cn/models/cix/ai_model_hub_25_Q3/resolve/master/models/ComputeVision/Image_Classification/onnx_mobilenet_v2/model/mobilenet_v2.onnx
wget -O mobilenetv2-7.onnx https://www.modelscope.cn/models/cix/ai_model_hub_25_Q3/resolve/master/models/ComputeVision/Image_Classification/onnx_mobilenet_v2/model/mobilenetv2-7.onnx
```

</NewCodeBlock>

### 项目结构

```txt
├── cfg
├── datasets
├── inference_npu.py
├── inference_onnx.py
├── mobilenet_v2.cix
├── model
├── ReadMe.md
└── test_data
```

### 进行模型量化和转换

<NewCodeBlock tip="Linux PC" type="PC">

```bash
cd ..
cixbuild cfg/onnx_mobilenet_v2build.cfg
```

</NewCodeBlock>

:::info[推送到板端]
完成模型转换之后需要将 cix 模型文件推送到板端。
:::

### 测试主机推理

#### 运行推理脚本

<NewCodeBlock tip="Linux PC" type="PC">

```bash
python3 inference_onnx.py --images test_data --onnx_path model/mobilenetv2-7.onnx
```

</NewCodeBlock>

#### 模型推理结果

<NewCodeBlock tip="Linux PC" type="PC">

```bash
$ python3 inference_onnx.py --images test_data --onnx_path model/mobilenetv2-7.onnx
image path : test_data/ILSVRC2012_val_00024154.JPEG
Ibizan hound, Ibizan Podenco
image path : test_data/ILSVRC2012_val_00021564.JPEG
coucal
image path : test_data/ILSVRC2012_val_00002899.JPEG
rock python, rock snake, Python sebae
image path : test_data/ILSVRC2012_val_00045790.JPEG
Yorkshire terrier
image path : test_data/ILSVRC2012_val_00037133.JPEG
ice bear, polar bear, Ursus Maritimus, Thalarctos maritimus
```

</NewCodeBlock>

### 进行 NPU 部署

#### 运行推理脚本

<NewCodeBlock tip="O6 / O6N" type="device">

```bash
python3 inference_npu.py --images test_data --model_path mobilenet_v2.cix
```

</NewCodeBlock>

#### 模型推理结果

<NewCodeBlock tip="O6 / O6N" type="device">

```bash
$ python3 inference_npu.py --images test_data --model_path mobilenet_v2.cix
npu: noe_init_context success
npu: noe_load_graph success
Input tensor count is 1.
Output tensor count is 1.
npu: noe_create_job success
image path : ./test_data/ILSVRC2012_val_00037133.JPEG
ice bear, polar bear, Ursus Maritimus, Thalarctos maritimus
image path : ./test_data/ILSVRC2012_val_00021564.JPEG
coucal
image path : ./test_data/ILSVRC2012_val_00024154.JPEG
Ibizan hound, Ibizan Podenco
image path : ./test_data/ILSVRC2012_val_00002899.JPEG
boa constrictor, Constrictor constrictor
image path : ./test_data/ILSVRC2012_val_00045790.JPEG
Yorkshire terrier
npu: noe_clean_job success
npu: noe_unload_graph success
npu: noe_deinit_context success
```

</NewCodeBlock>
