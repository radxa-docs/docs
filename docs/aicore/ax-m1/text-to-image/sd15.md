---
sidebar_position: 0
---

# StableDiffusion 1.5 LCM

此文档讲解如何在安装了瑞莎智核 AX-M1 的 host 设备上运行 [StableDiffusion 1.5 LCM](https://huggingface.co/latent-consistency/lcm-lora-sdv1-5) 示例应用。

## 创建虚拟环境

<NewCodeBlock tip="Host" type="device">

```bash
python3 -m venv .venv && source .venv/bin/activate
```

</NewCodeBlock>

## 下载示例应用仓库

<NewCodeBlock tip="Host" type="device">

```bash
pip3 install -U "huggingface_hub"
hf download AXERA-TECH/lcm-lora-sdv1-5 --local-dir ./lcm-lora-sdv1-5
cd lcm-lora-sdv1-5
```

</NewCodeBlock>

## 示例使用

### 安装 python 依赖

<NewCodeBlock tip="Host" type="device">

```bash
pip3 install -r requirements.txt
pip3 install https://github.com/AXERA-TECH/pyaxengine/releases/download/0.1.3.rc1/axengine-0.1.3-py3-none-any.whl
```

</NewCodeBlock>

### 模型推理

<NewCodeBlock tip="Host" type="device">

```bash
python run_txt2img_axe_infer.py
```

</NewCodeBlock>

```bash
(.venv) rock@rock-5b-plus:~/ssd/axera/lcm-lora-sdv1-5$ python run_txt2img_axe_infer.py
[INFO] Available providers:  ['AXCLRTExecutionProvider']
The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.
0it [00:00, ?it/s]
prompt: Self-portrait oil painting, a beautiful cyborg with golden hair, 8k
text_tokenizer: ./models/tokenizer
text_encoder: ./models/text_encoder
unet_model: ./models/unet.axmodel
vae_decoder_model: ./models/vae_decoder.axmodel
time_input: ./models/time_input_txt2img.npy
save_dir: ./txt2img_output_axe.png
[INFO] Using provider: AXCLRTExecutionProvider
[INFO] SOC Name: AX650N
[INFO] VNPU type: VNPUType.DISABLED
[INFO] Compiler version: 3.4 9215b7e5
text encoder take 3108.7ms
[INFO] Using provider: AXCLRTExecutionProvider
[INFO] SOC Name: AX650N
[INFO] VNPU type: VNPUType.DISABLED
[INFO] Compiler version: 3.3 972f38ca
[INFO] Using provider: AXCLRTExecutionProvider
[INFO] SOC Name: AX650N
[INFO] VNPU type: VNPUType.DISABLED
[INFO] Compiler version: 3.3 972f38ca
load models take 15541.5ms
unet once take 433.6ms
unet once take 433.6ms
unet once take 433.2ms
unet once take 433.4ms
unet loop take 1738.7ms
vae inference take 920.2ms
save image take 187.5ms
```

<div style={{textAlign: 'center'}}>
   <img src="/img/aicore-ax-m1/txt2img_output_axe.webp"/>
   StableDiffusion 1.5 LCM demo output
</div>
