## RKLLM Overview

RKLLM helps you deploy LLM models to Rockchip SoCs. Currently supported chips include the RK3588 / RK3576 / RK3562 series.

RKLLM architecture:

![rkllm_1.webp](/img/general-tutorial/rknn/rkllm_1.webp)

#### Supported models

- [LLAMA models](https://huggingface.co/meta-llama)
- [TinyLLAMA models](https://huggingface.co/TinyLlama)
- [Qwen models](https://huggingface.co/models?search=Qwen/Qwen)
- [Phi models](https://huggingface.co/models?search=microsoft/phi)
- [ChatGLM3-6B](https://huggingface.co/THUDM/chatglm3-6b/tree/103caa40027ebfd8450289ca2f278eac4ff26405)
- [Gemma2](https://huggingface.co/collections/google/gemma-2-release-667d6600fd5220e7b967f315)
- [Gemma3](https://huggingface.co/collections/google/gemma-3-release-67c6c6f89c4f76621268bb6d)
- [InternLM2 models](https://huggingface.co/collections/internlm/internlm2-65b0ce04970888799707893c)
- [MiniCPM models](https://huggingface.co/collections/openbmb/minicpm-65d48bf958302b9fd25b698f)
- [TeleChat models](https://huggingface.co/Tele-AI)
- [Qwen2-VL-2B-Instruct](https://huggingface.co/Qwen/Qwen2-VL-2B-Instruct)
- [MiniCPM-V-2_6](https://huggingface.co/openbmb/MiniCPM-V-2_6)
- [DeepSeek-R1-Distill](https://huggingface.co/collections/deepseek-ai/deepseek-r1-678e1e131c0169c0bc89728d)
- [Janus-Pro-1B](https://huggingface.co/deepseek-ai/Janus-Pro-1B)
- [InternVL2-1B](https://huggingface.co/OpenGVLab/InternVL2-1B)
- [Qwen2.5-VL-3B-Instruct](https://huggingface.co/Qwen/Qwen2.5-VL-3B-Instruct)
- [Qwen3](https://huggingface.co/collections/Qwen/qwen3-67dd247413f0e2e4f653967f)

## Download the SDK

Go to your SDK directory and clone the RKLLM repository.

<NewCodeBlock tip="X86 Linux PC" type="PC">

```bash
cd RKSDK
git clone -b release-v1.2.3 https://github.com/airockchip/rknn-llm.git
```

</NewCodeBlock>

## Install Miniforge

<NewCodeBlock tip="X86 Linux PC" type="PC">

```bash
wget https://github.com/conda-forge/miniforge/releases/download/25.11.0-0/Miniforge3-25.11.0-0-Linux-x86_64.sh
chmod +x Miniforge3-25.11.0-0-Linux-x86_64.sh
bash Miniforge3-25.11.0-0-Linux-x86_64.sh
```

</NewCodeBlock>

## Create a virtual environment

<NewCodeBlock tip="X86 Linux PC" type="PC">

```bash
conda create -n rkllm python=3.12
```

</NewCodeBlock>

## Activate the virtual environment

<NewCodeBlock tip="X86 Linux PC" type="PC">

```bash
conda activate rkllm
```

</NewCodeBlock>

## Install dependencies

<NewCodeBlock tip="X86 Linux PC" type="PC">

```bash
cd rknn-llm/rkllm-toolkit/packages
pip install rkllm_toolkit-1.2.3-cp312-cp312-linux_x86_64.whl
```

</NewCodeBlock>

## Verify the installation

If the following commands run without errors, the installation is successful.

<NewCodeBlock tip="X86 Linux PC" type="PC">

```bash
$python3
>>>from rkllm.api import RKLLM
```

</NewCodeBlock>

## Toolchain for building on-device examples

To build the on-device runtime examples, you need a cross-compilation toolchain.

Download: [Cross compilation toolchain](https://developer.arm.com/-/media/files/downloads/gnu/11.2-2022.02/binrel/gcc-arm-11.2-2022.02-x86_64-aarch64-none-linux-gnu.tar.xz?rev=33c6e30e5ac64e6dba8f0431f2c35f1b&revision=33c6e30e-5ac6-4e6d-ba8f-0431f2c35f1b&hash=632C6C0BD43C3E4B59CA8A09A7055D30).

Extract it after downloading.

Before building, export the compiler path so the scripts can find the toolchain.

<NewCodeBlock tip="X86 Linux PC" type="PC">

```bash
export GCC_COMPILER=/path/to/your/gcc/bin/aarch64-linux-gnu
```

</NewCodeBlock>

## Device driver requirements

RKLLM requires a newer RKNPU driver. Before running RKLLM Runtime on the device, confirm that your RKNPU driver is **v0.9.8**.

:::tip
Radxa OS 6.1 images may ship with RKNPU driver **0.9.6** by default.
Upgrade via `sudo rsetup` -> `System` -> `System Update` to get RKNPU driver **0.9.8**.
After upgrading, run **`sudo apt autopurge`** and reboot.
:::

Check the driver version:

<NewCodeBlock tip="Radxa OS" type="device">

```bash
$ sudo cat /sys/kernel/debug/rknpu/version
RKNPU driver: v0.9.8
```

</NewCodeBlock>

Optional: build the NPU driver manually

If you are using a non-official firmware image, you may need to update the kernel.
The RKNPU driver package supports two major kernel versions:
[kernel-5.10](https://github.com/radxa/kernel/tree/stable-5.10-rock5) and
[kernel-6.1](https://github.com/radxa/kernel/tree/linux-6.1-stan-rkr1).
You can confirm the exact version in the kernel root `Makefile`. The general update steps are:

1. Download [rknpu_driver_0.9.8_20241009.tar.bz2](https://github.com/airockchip/rknn-llm/tree/release-v1.2.1b1/rknpu-driver).

2. Extract it and overwrite the `rknpu` driver sources in your kernel tree.

3. Rebuild the kernel.

4. Flash the newly built kernel to the device.

## Clone the repository on the device

RKLLM Runtime provides C/C++ APIs for Rockchip NPUs to help you deploy RKLLM models and accelerate LLM applications.

Clone the RKLLM repository on the device:

<NewCodeBlock tip="Radxa OS" type="device">

```bash
git clone -b release-v1.2.3 https://github.com/airockchip/rknn-llm.git
```

</NewCodeBlock>
