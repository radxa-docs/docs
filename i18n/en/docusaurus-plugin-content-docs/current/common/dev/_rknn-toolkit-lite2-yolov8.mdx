:::tip
This document demonstrates how to run on-board inference of the YOLOv8 object detection model on the RK3588. For the required environment setup, please refer to [RKNN Installation](./rknn_install).  
:::

This example uses a pretrained ONNX model from the [rknn_model_zoo](https://github.com/airockchip/rknn_model_zoo) as an example to illustrate the complete process of converting the model and performing inference on the board. The target platform for this example is RK3588.

Using RKNN to deploy YOLOv8 involves two steps:

- On a PC, use **rknn-toolkit2** to convert models from different frameworks into RKNN format.
- On the board, use **rknn-toolkit2-lite**'s Python API for model inference.

### Model Conversion on PC

**Radxa has provided a pre-converted `yolov8.rknn` model. Users can skip this section and refer to [YOLOv8 Inference on Board](#yolov8-inference-on-board).**

- If using Conda, activate the RKNN environment first:

  <NewCodeBlock tip="X86 Linux PC" type="PC">

  ```bash
  conda activate rknn
  ```

  </NewCodeBlock>

- Download the YOLOv8 ONNX model:

  <NewCodeBlock tip="X86 Linux PC" type="PC">

  ```bash
  cd rknn_model_zoo/examples/yolov8/model
  # Download the pretrained yolov8n.onnx model
  bash download_model.sh
  ```

  </NewCodeBlock>

  If you encounter network issues, you can download the corresponding model manually from [this page](https://github.com/airockchip/rknn_model_zoo?tab=readme-ov-file#model-support) and place it in the appropriate folder.

- Convert the ONNX model to the RKNN format using **rknn-toolkit2**:

  <NewCodeBlock tip="X86 Linux PC" type="PC">

  ```bash
  cd rknn_model_zoo/examples/yolov8/python
  python3 convert.py ../model/yolov8n.onnx rk3588
  ```

  </NewCodeBlock>

  **Parameter Explanation**:

  - `<onnx_model>`: Specifies the path to the ONNX model.
  - `<TARGET_PLATFORM>`: Specifies the NPU platform name. Options include `rk3562, rk3566, rk3568, rk3576, rk3588, rk1808, rv1109, rv1126`.
  - `<dtype> (optional)`: Specifies the data type as `i8` (for int8 quantization) or `fp` (for fp16 quantization). The default is `i8`.
  - `<output_rknn_path> (optional)`: Specifies the path for saving the RKNN model. By default, it is saved in the same directory as the ONNX model with the filename `yolov8.rknn`.

- Copy the `yolov8n.rknn` model to the target board.

### YOLOv8 Inference on Board

- Download the `rknn-model-zoo-rk3588` package to obtain the YOLOv8 demo (includes the pre-converted `yolov8.rknn` model):

  <NewCodeBlock tip="Radxa OS" type="device">

  ```bash
  sudo apt install rknn-model-zoo-rk3588
  ```

  </NewCodeBlock>

  If using a CLI version, you can download the package manually from the [deb package download page](https://github.com/radxa-pkg/rknn_model_zoo/releases/tag/1.6.0-1).

- Run the YOLOv8 example code:

  If using a model converted on the PC, copy it to the board and specify the model path using the `--model_path` parameter:

  <NewCodeBlock tip="Radxa OS" type="device">

  ```bash
  cd /usr/share/rknn_model_zoo/examples/yolov8/python
  sudo python3 yolov8.py --model_path ../model/yolov8.rknn --img_save
  ```

  </NewCodeBlock>

  Example output:

  <NewCodeBlock tip="Results" type="device">

  ```bash
  $ sudo python3 yolov8.py --model_path ../model/yolov8.rknn --img_save
  import rknn failed, try to import rknnlite
  --> Init runtime environment
  I RKNN: [09:01:01.819] RKNN Runtime Information, librknnrt version: 1.6.0
  I RKNN: [09:01:01.819] RKNN Driver Information, version: 0.8.2
  W RKNN: [09:01:01.819] Current driver version: 0.8.2, recommend to upgrade the driver to version >= 0.8.8
  I RKNN: [09:01:01.819] RKNN Model Information, version: 6, target platform: rk3588
  W RKNN: [09:01:01.836] Query dynamic range failed. Ret code: RKNN_ERR_MODEL_INVALID.
  done
  Model-../model/yolov8.rknn is rknn model, starting val
  infer 1/1

  IMG: bus.jpg
  person @ (211 241 282 507) 0.872
  person @ (109 235 225 536) 0.860
  person @ (477 225 560 522) 0.856
  person @ (79 327 116 513) 0.306
  bus  @ (95 136 549 449) 0.860
  Detection result saved to ./result/bus.jpg
  ```

  </NewCodeBlock>

  **Parameter Explanation**:

  - `--model_path`: Specifies the RKNN model path.
  - `--img_folder`: Specifies the folder containing images for inference. Default is `../model`.
  - `--img_save`: Whether to save the inference result images to the `./result` folder. Default is `False`.

- All inference results are saved in the `./result` folder.

<img width="550" src="/en/img/general-tutorial/rknn/result.webp" />
