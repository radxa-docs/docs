This document describes how to use the [QAI AppBuilder](../qai-appbuilder) Python API to run inference with the [GoogLeNet](https://aihub.qualcomm.com/models/googlenet?domain=Computer+Vision&useCase=Image+Classification&chipsets=qualcomm-qcs6490-proxy) object recognition model on Qualcomm® Hexagon™ Processor (NPU).

**Supported Devices**

| Device                | SoC     |
| --------------------- | ------- |
| Dragon Q6A            | QCS6490 |
| Fogwise® AIRbox Q900 | QCS9075 |

## Install QAI AppBuilder

:::tip

1. Please install QAI AppBuilder according to [**QAI AppBuilder Installation Guide**](../qai-appbuilder#installation-methods).

2. Please configure QAIRT environment variables according to [**Configure QAIRT Environment Variables**](../qai-appbuilder#configure-qairt-environment-variables).
   :::

## Run the Example

### Install Dependencies

<NewCodeBlock tip="Device" type="device">

```bash
pip3 install requests tqdm qai-hub py3_wget opencv-python torch torchvision
```

</NewCodeBlock>

### Run the Script

- Navigate to the example directory

      <Tabs>

  <TabItem value="QCS6490">

         <NewCodeBlock tip="Device" type="device">

         ```bash
         cd ai-engine-direct-helper/samples/linux/python
         ```

          </NewCodeBlock>


          </TabItem>

          <TabItem value="QCS9075">

         <NewCodeBlock tip="Device" type="device">

          ```bash
          cd ai-engine-direct-helper/samples/python
          ```

          </NewCodeBlock>

      </TabItem>

      </Tabs>

- Prepare input image. The following image is used as an example:

  {" "}

  <div style={{ textAlign: "center" }}>
    <img src="/en/img/dragon/q6a/test_image.webp" style={{ width: "65%" }} />
    input image
  </div>

- Run inference

    <NewCodeBlock tip="Device" type="device">

  ```bash
  python3 googlenet/googlenet.py
  ```

    </NewCodeBlock>

  ```bash
  $ python3 googlenet/googlenet.py
       0.0ms [WARNING]  <W> Initializing HtpProvider

  /prj/qct/webtech_scratch20/mlg_user_admin/qaisw_source_repo/rel/qairt-2.37.1/point_release/SNPE_SRC/avante-tools/prebuilt/dsp/hexagon-sdk-5.5.5/ipc/fastrpc/rpcmem/src/rpcmem_android.c:38:dummy call to rpcmem_init, rpcmem APIs will be used from libxdsprpc
       0.0ms [WARNING]  <W> This META does not have Alloc2 Support

       0.0ms [WARNING]  <W> This META does not have Alloc2 Support

       0.0ms [WARNING]  <W> This META does not have Alloc2 Support

       0.0ms [WARNING]  <W> This META does not have Alloc2 Support

     157.6ms [WARNING] Time: Read model file to memory. 8.91

       0.0ms [WARNING]  <W> This META does not have Alloc2 Support

       0.0ms [WARNING]  <W> This META does not have Alloc2 Support

       0.0ms [WARNING]  <W> This META does not have Alloc2 Support

       0.0ms [WARNING]  <W> This META does not have Alloc2 Support

       0.0ms [WARNING]  <W> This META does not have Alloc2 Support

       0.0ms [WARNING]  <W> This META does not have Alloc2 Support

       0.0ms [WARNING]  <W> This META does not have Alloc2 Support

     180.6ms [WARNING] Time: contextCreateFromBinary. 22.97

     180.7ms [WARNING] Time: UnmapViewOfFile. 0.00

     181.6ms [WARNING] Time: model_initialize googlenet 181.55

     255.7ms [WARNING] Time: model_inference googlenet 2.67

  Top 5 predictions for image:

  Samoyed 0.948613584
  West Highland White Terrier 0.0060515446
  Alaskan tundra wolf 0.0052576731
  Pomeranian 0.0047871661
  Chow Chow 0.0035575195
       0.0ms [WARNING]  <W> This META does not have Alloc2 Support

       0.0ms [WARNING]  <W> This META does not have Alloc2 Support

       0.0ms [WARNING]  <W> This META does not have Alloc2 Support

       0.0ms [WARNING]  <W> This META does not have Alloc2 Support

  /prj/qct/webtech_scratch20/mlg_user_admin/qaisw_source_repo/rel/qairt-2.37.1/point_release/SNPE_SRC/avante-tools/prebuilt/dsp/hexagon-sdk-5.5.5/ipc/fastrpc/rpcmem/src/rpcmem_android.c:42:dummy call to rpcmem_deinit, rpcmem APIs will be used from libxdsprpc
     353.7ms [WARNING] Time: model_destroy googlenet 93.43

  ```

  The output shows that `Samoyed` has the highest confidence score, which matches the content of the input image.
