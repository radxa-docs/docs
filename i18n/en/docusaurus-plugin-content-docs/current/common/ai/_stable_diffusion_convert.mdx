Stable Diffusion is a text-to-image generation model based on latent diffusion. It gradually adds and removes noise in latent space to turn random noise into images that match a text prompt.
In recent years, Stable Diffusion has evolved rapidly, with many community-optimized variants that improve quality, speed, and efficiency.
This guide uses **Stable Diffusion LCM Dreamshaper V7**, a lightweight variant that applies Latent Consistency Model (LCM) acceleration to generate high-quality images with very few steps (as few as **4 steps**).
This document shows how to deploy the model to the NPU on Rockchip SoCs using the RKNN toolchain for efficient, low-latency on-device generation.

:::tip
This document uses RK3588 and Dreamshaper V7 as an example.
You need to set up the RKNN environment on your PC first. See [RKNN Installation](./rknn-install).
:::

## Model Download

**Radxa provides pre-converted RKNN models and runnable files (output resolution: 256×256). You can download and use them directly:**

- **Download the model files using `modelscope`**

  - **Create a directory for the model files**

<NewCodeBlock tip="Linux PC" type="PC">

```bash
mkdir sd-lcm-rknn && cd sd-lcm-rknn
```

</NewCodeBlock>

- **Install `modelscope` via pip**

<NewCodeBlock tip="Linux PC" type="PC">

```bash
# Use a recent Python version to avoid compatibility issues.
pip3 install modelscope
```

</NewCodeBlock>

- **Download the `Stable-Diffusion-LCM_RKNN` package**

<NewCodeBlock tip="Linux PC" type="PC">

```bash
modelscope download --model radxa/Stable-Diffusion-LCM_RKNN
```

</NewCodeBlock>

## Model Conversion (Optional)

**If you want a different output resolution, you can convert the model yourself:**

- **Download the ONNX model from Hugging Face and convert it to RKNN**

  - **Create a directory for the model files**

<NewCodeBlock tip="Linux PC" type="PC">

```bash
mkdir sd-lcm-rknn && cd sd-lcm-rknn
```

</NewCodeBlock>

- **Clone the model repository**

<NewCodeBlock tip="Linux PC" type="PC">

```bash
# Requires git lfs. Install it first if needed.
git lfs install
git clone https://huggingface.co/thanhtantran/Stable-Diffusion-1.5-LCM-ONNX-RKNN2
```

</NewCodeBlock>

- **Activate the virtual environment**

<NewCodeBlock tip="Linux PC" type="PC">

```bash
conda activate your_rknn_env
```

</NewCodeBlock>

- **Optionally run `run_onnx-lcm.py` to verify the ONNX model**

<NewCodeBlock tip="Linux PC" type="PC">

```bash
# Use -h to view help.
python run_onnx-lcm.py -i ./model -o ./images --prompt "Majestic mountain landscape with snow-capped peaks, autumn foliage in vibrant reds and oranges, a turquoise river winding through a valley, crisp and serene atmosphere, ultra-realistic style."
```

</NewCodeBlock>

- **Run `convert-onnx-to-rknn.py` to convert the model**

<NewCodeBlock tip="Linux PC" type="PC">

```bash
# Use -h to view help. Replace N with your desired resolution.
# The converted model will only output at that resolution.
python convert-onnx-to-rknn.py -i ./model -r NxN
```

</NewCodeBlock>

- **Arrange files in the following directory layout**

```txt
---sd-lcm-rknn
     ---model
         ---scheduler
         ---scheduler_config.json
     ---text_encoder
         ---config.json
         ---model.rknn
     ---unet
         ---config.json
         ---model.rknn
     ---vae_decoder
         ---config.json
         ---model.rknn
     ---run_rknn-lcm.py
```

## On-device Deployment

- **Copy the RKNN models and runtime files to the device**

  - **Enter the directory on the device**

<NewCodeBlock tip="Radxa SBC" type="device">

```bash
cd sd-lcm-rknn
```

</NewCodeBlock>

- **Create a Python virtual environment**

<NewCodeBlock tip="Radxa SBC" type="device">

```bash
python -m venv .venv
```

</NewCodeBlock>

- **Activate the virtual environment**

<NewCodeBlock tip="Radxa SBC" type="device">

```bash
source .venv/bin/activate
```

</NewCodeBlock>

- **Install dependencies**

<NewCodeBlock tip="Radxa SBC" type="device">

```bash
pip3 install diffusers pillow "numpy<2.0" torch transformers rknn-toolkit-lite2
```

</NewCodeBlock>

- **Run the script**

<NewCodeBlock tip="Radxa SBC" type="device">

```bash
# Use -h to view help. If you converted the model yourself, adjust the resolution accordingly.
python ./run_rknn-lcm.py -i ./model -o ./images -s 256x256 --prompt "Majestic mountain landscape with snow-capped peaks, autumn foliage in vibrant reds and oranges, a turquoise river winding through a valley, crisp and serene atmosphere, ultra-realistic style."
```

</NewCodeBlock>

## Results and Performance

- **Example output (256×256 on-device)**

![sb-lcm-mountain.webp](/img/rock5b/sb-lcm-mountain.webp)

- **Single-run timing (for reference only):**

```txt
text_encoder load time: Took 0.7 seconds.
unet load time: Took 2.8 seconds.
vae_decoder load time: Took 0.4 seconds.
Prompt encoding time: 0.08s
Inference time: 4.55s
Decode time: 3.15s
Total time: 7.78s
```
